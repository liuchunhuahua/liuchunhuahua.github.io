<!doctype html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="seq2seq," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="这篇文章主要是根据tensorflow中的英法翻译模型的代码，介绍了代码中所使用的常见的深度学习所使用的方法。">
<meta property="og:type" content="article">
<meta property="og:title" content="Seq2Seq-In-Tensorflow">
<meta property="og:url" content="http://liuchunhuahua.git.io/2017/03/09/Seq2seq-In-Tensorflow/index.html">
<meta property="og:site_name" content="Huahua's blog">
<meta property="og:description" content="这篇文章主要是根据tensorflow中的英法翻译模型的代码，介绍了代码中所使用的常见的深度学习所使用的方法。">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/encoder-decoder-x1x2x3.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/WMT_data_set.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/translate.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/seq2seq_function.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/encoder-decoder-xyzw.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/attention%20formula.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/attention_grammer.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/sampled_softmax.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/static%20padding.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/dynamic%20padding.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/bucketing.png">
<meta property="og:image" content="http://ojigevmih.bkt.clouddn.com/fakedata_seq2seq_result.png">
<meta property="og:updated_time" content="2017-03-09T03:07:52.948Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Seq2Seq-In-Tensorflow">
<meta name="twitter:description" content="这篇文章主要是根据tensorflow中的英法翻译模型的代码，介绍了代码中所使用的常见的深度学习所使用的方法。">
<meta name="twitter:image" content="http://ojigevmih.bkt.clouddn.com/encoder-decoder-x1x2x3.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://liuchunhuahua.git.io/2017/03/09/Seq2seq-In-Tensorflow/"/>





  <title> Seq2Seq-In-Tensorflow | Huahua's blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Huahua's blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle">love coding,enjoy life</p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://liuchunhuahua.git.io/2017/03/09/Seq2seq-In-Tensorflow/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="chunhualiu">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="http://ojigevmih.bkt.clouddn.com/20170110.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Huahua's blog">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Huahua's blog" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Seq2Seq-In-Tensorflow
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-09T10:46:18+08:00">
                2017-03-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这篇文章主要是根据tensorflow中的英法翻译模型的代码，介绍了代码中所使用的常见的深度学习所使用的方法。</p>
<a id="more"></a>
<h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1.基础知识"></a>1.基础知识</h2><p>第一部分主要介绍Tensorflow的基本思想，Neural Machine Translation(NMT),英法翻译数据集。</p>
<h3 id="1-1-Tensorflow简介"><a href="#1-1-Tensorflow简介" class="headerlink" title="1.1 Tensorflow简介"></a>1.1 Tensorflow简介</h3><p>这篇读书笔记不仅仅是一份代码解读，最重要的是学习这份代码中所包含的一个个精妙的机器学习的机制。包括candidate sample,output_projection,seq2seq model,attention mechinism等等，在下面的笔记中我会一一介绍这些机制或者模型的理论以及在Tensorflow的代码中是如何去进行实现的。</p>
<p>在进行代码解读之前，首先需要简单的介绍一下Tensorflow是什么，怎么用的。<br>Tensorflow是一个编程系统，其实就像是一门新的语言，其中提供了很多库函数，包括一些常见的数学计算和深度学习的模型，可以对其进行调用来完成自己的任务。<br>在介绍它的核心思想之前，先了解几个基本的概念：  </p>
<p>(1)  Tensorflow使用graph 来表示计算任务，graph由很多operation(op)构成。<br>(2)  在Session中的context执行graph，在graph执行前开启Session。<br>(3)  使用 Tensor 表示任意的数据。（一个Tensor其实就是一个类型化的多维数组）<br>(4)  通过 Variable 维护状态。<br>(5)  使用 feed 和 fetch 为任意的operation 赋值或者从其中获取数据。</p>
<p>tf核心思想就是使用图来表示计算任务，在图中有很多的op,这些op定义了你要做的事情是什么，比如常见的加减乘除op，数组op，矩阵op，网络构建所需要的op等等。</p>
<p>构建图：对于每一个任务来讲都是使用这些op来构建一个图，在图的构建过程中是没有实         际的计算的，可以使用占位的方式来表示需要外部传入的数据。<br>执行图：图构建好之后，开始执行图。执行图需要开启一个Session，只有当开启一个Session的时候，使用feed将图中所需要的数据传入，调用Session.run()时图才会真正进行计算，图中op运算得到的值会以Tensor的形式返回。任务完成之后关闭Session.</p>
<p>在图的执行过程中可以将参数保存，在以后运行时可以将之前保存的参数重新载入图中计算。<br>注：Tensorflow在下文中简称tf。</p>
<h3 id="1-2-关于Neural-Machine-Learning-NMT-简介"><a href="#1-2-关于Neural-Machine-Learning-NMT-简介" class="headerlink" title="1.2 关于Neural Machine Learning(NMT)简介"></a>1.2 关于Neural Machine Learning(NMT)简介</h3><p>NMT的目标就是构建一个端到端的神经网络来解决翻译问题，而不是像传统的MT那样复杂。主流的NMT方法就是encoder-decoder模型，它的主要思想使用两个RNN(或LSTM/Bi-LSTM/GRU)模型。<br>一个作为encoder，将源语言(比如英语)的句子编码成一个固定长度的向量，用该向量表示源语言句子的语义表示。<br>另一个作为decoder，将encoder生成的向量和目标语言(比如法语)的输入句子一起传递给decoder来产生最后的输出。decoder可以与encoder相同也可以不相同，decoder的作用和构建一个神经语言模型的思想是类似的，使用当前词去预测下一个词。模型图示例如下：<br><img src="http://ojigevmih.bkt.clouddn.com/encoder-decoder-x1x2x3.png" alt=""><br>(picture from: Learning Phrase Representations using RNN encoder–decoder for Statistical Machine Translation)<br>encoder_inputs： x1 x2 …xT  —-&gt;encoder—–&gt;c<br>decoder_inputs: y1 y2 …yT<br>C和yt-1一起   —-&gt;decoder  —–&gt; yt  </p>
<p>encoder-decoder模型是一个有监督的模型，decoder在训练阶段可以提供正确的输出结果的,以此来提高模型的鲁棒性，在测试阶段则只使用decoder的输出。<br>为了提高模型的性能，还可以引入Attention   Mechanism来更好的利用源语言的信息，在即将解读的这份英法翻译代码中就使用了Attention。  </p>
<h3 id="1-3-英法翻译例子代码介绍"><a href="#1-3-英法翻译例子代码介绍" class="headerlink" title="1.3 英法翻译例子代码介绍"></a>1.3 英法翻译例子代码介绍</h3><h4 id="1-3-1-数据集"><a href="#1-3-1-数据集" class="headerlink" title="1.3.1  数据集"></a>1.3.1  数据集</h4><p>数据集是一个叫WMT’15的数据集，包括了英法翻译的训练集和测试集。<br>    数据规模如下：<br> <img src="http://ojigevmih.bkt.clouddn.com/WMT_data_set.png" alt=""></p>
<p>  数据集的下载地址如下：<br>  <a href="http://www.statmt.org/wmt15/translation-task.html" target="_blank" rel="external">http://www.statmt.org/wmt15/translation-task.html</a></p>
<p>  上面的id训练集和id测试集是经过代码处理后生成的，已经将每一个单词转换成词表中所对应的id号。</p>
<h4 id="1-3-2-代码构成"><a href="#1-3-2-代码构成" class="headerlink" title="1.3.2  代码构成"></a>1.3.2  代码构成</h4><p>英法翻译代码在github中可以找到，存放路径：tensorflow/tensorflow/models/rnn/translate<br>代码的构成见下图：<br><img src="http://ojigevmih.bkt.clouddn.com/translate.png" alt=""><br>(picture from:huahua)</p>
<p>第一次运行代码时需要下载数据，会比较慢。也可以直接用迅雷下载好之后再运行代码。</p>
<p>这份代码中最核心的部分就是seq2seq_model.py/moedel_with_buckets()，该函数最重要的是两部分：调用一个seq2seq的模型生成output,调用一个计算损失的函数。<br>在翻译模型例子代码中seq2seq模型选择的是embedding_attention_seq2seq,损失函数选择的是sampled_softmax。<br>在tf的0.12版本中embedding_attention_seq2seq位于：<br>tensorflow/tensorflow/python/ops/seq2seq.py</p>
<p>seq2seq.py中实现了大部分的seq2seq模型。主要有如下几个：<br><img src="http://ojigevmih.bkt.clouddn.com/seq2seq_function.png" alt=""><br>(picture from:huahua)<br>第一个basic_rnn_seq2seq中使用最基本的RNN单元，一个激活函数，输出和状态相同。<br>第二个tied_rnn_seq2seq和第一个不同的在于encoder和decoder共享参数。<br>第三个embedding_rnn_seq2seq中给数据加了词向量，第一个和第二个一般是外面将词变成词向量后传入，这里可以直接内部生成。<br>第四个也是内部加入了词向量，与第二个一样有共享参数的特征。<br>第五个是embedding_attetnion_seq2seq，在3的基础上引入了attention机制。<br>在接下来的代码中会主要介绍embedding_attention_seq2seq,这是一个比较复杂的seq2seq模型，里面涉及到很多的机制，比如attention mechanism, output_projection,sampled_softmax,feed_previous,bucketing等等。我们将在接下的部分进行详细讲解。</p>
<h2 id="2-embedding-attention-seq2seq中的机制"><a href="#2-embedding-attention-seq2seq中的机制" class="headerlink" title="2. embedding_attention_seq2seq中的机制"></a>2. embedding_attention_seq2seq中的机制</h2><h3 id="2-1-sequence2sequence-model介绍"><a href="#2-1-sequence2sequence-model介绍" class="headerlink" title="2.1 sequence2sequence model介绍"></a>2.1 sequence2sequence model介绍</h3><p>Sequence2sequence一般写作seq2seq，它相当于是一个翻译模型，将一个sequence翻译成另一个sequence，使用的是encoder-decoder模型的思想。<br>1.2中的图少了一部分实际操作的信息。<br>比如：<br>(1) 在实际操作的时候会将encoder_inputs进行一个反转操作(CBA变成ABC)，再传递给encoder进行编码。<br>(2) 在decoder_inputs的第一个元素前加上一个形式标记，例如下图中的<eos>，利用</eos></p>
<p><eos>和encoder_outputs(WXYZ)来预测decoder_output的第一个元素，如下图中的W。</eos></p>
<p><img src="http://ojigevmih.bkt.clouddn.com/encoder-decoder-xyzw.png" alt=""><br>(picture from:Sequence to Sequence Learning with Neural Networks)  </p>
<h3 id="2-2-Attention-Mechanism"><a href="#2-2-Attention-Mechanism" class="headerlink" title="2.2 Attention Mechanism"></a>2.2 Attention Mechanism</h3><h4 id="2-2-1-Attention-Mechanism-Theory"><a href="#2-2-1-Attention-Mechanism-Theory" class="headerlink" title="2.2.1 Attention Mechanism Theory"></a>2.2.1 Attention Mechanism Theory</h4><p>关于attention mechanism在attention_decoder()中直接引用的是Grammar as a Foreign Language这篇论文中的思路，但是attention mechanism最早提出是在Neural Machine Translation By Joint Learning to Align and Translate这篇文章中。</p>
<p>简单说，attention mechanism，就是把encoder每一个时间得到的output保存。<br>然后做一个“对齐”的映射，在decoder的某个时间点的时候，不仅考虑该时间点的state、decoder_input，之前encoder的ouput中哪些部分是重要的，来影响当前的输出。</p>
<p>具体的计算公式如下：</p>
<p><img src="http://ojigevmih.bkt.clouddn.com/attention%20formula.png" alt=""><br>(pic from:Neural Machine Translation By Joint Learning to Align and Translate)</p>
<p>上图中：t时刻的output是和t-1时刻的output、t时刻的state、t时刻的c有关系的。<br>c是对encoder的output进行加权求和得到的，权重的计算方法见图中的左下角。<br>t时刻的state由t-1时刻decoder的state和t-1时刻decoder的output以及t时刻的c生成。<br>这便是attention mechanism的理论部分。  </p>
<h4 id="2-2-2-Attention-Mechanism-Code"><a href="#2-2-2-Attention-Mechanism-Code" class="headerlink" title="2.2.2 Attention Mechanism Code"></a>2.2.2 Attention Mechanism Code</h4><h5 id="1-attention-部分"><a href="#1-attention-部分" class="headerlink" title="1.attention 部分"></a>1.attention 部分</h5><p>在tf中attention mechanism的实现主要是在seq2seq.py中的attetnion_decoder()中，代码中的数学公式，主要参考论文Grammar as a Foreign Language。<br>首先看公式：<br><img src="http://ojigevmih.bkt.clouddn.com/attention_grammer.png" alt=""><br>(picture from:Grammar as a Foreign Language)</p>
<p>hi表示decoder在t时刻的output,dt是t-1时刻产生的attetnion Tensor,dt’是新产生的attention Tensor。<br>产生attention Tensor的代码如下(seq2seq.py/attention_decoder/attention())：</p>
<pre><code>#query是decoder上一时刻产生的state,t=0时采用初始state
def attention(query):
  ds = []  # Results of attention reads will be stored here.
  for a in xrange(num_heads): #num_heads默认为1
    with variable_scope.variable_scope(&quot;Attention_%d&quot; % a):
      y = linear(query, attention_vec_size, True)
      y = array_ops.reshape(y, [-1, 1, 1, attention_vec_size])

      #y=W2*dt
      #hidden_features[a]=W1*hi(外部计算好的) 
      # Attention mask is a softmax of v^T * tanh(W1*hi+W2*dt).

      s = math_ops.reduce_sum(
          v[a] * math_ops.tanh(hidden_features[a] + y), [2, 3])
      a = nn_ops.softmax(s)   #得到权重Tensor a  
      # Now calculate the attention-weighted vector d=sum(ait*hi)
      d = math_ops.reduce_sum(
          array_ops.reshape(a, [-1, attn_length, 1, 1]) * hidden,
          [1, 2])
      ds.append(array_ops.reshape(d, [-1, attn_size]))
  return ds
  #最后得到的ds就是上图中的dt&apos;
</code></pre><h5 id="2-attention-decoder-核心代码流程"><a href="#2-attention-decoder-核心代码流程" class="headerlink" title="2.attention_decoder()  核心代码流程"></a>2.attention_decoder()  核心代码流程</h5><pre><code>  # First, we run the cell on a combination of the input and previous attention masks:
  #(1)计算t时刻的cell_output,state
  x = linear([inp] + attns, input_size, True)
  cell_output, state = cell(x, state)

  #(2)计算新的attns,new_attn = sum(softmax(V^T * tanh(W * attention_states + U * new_state)))，attention()在前面已经讲解。
  attns = attention(state)


  #(3)将t时刻的output和attention()的返回值attns相加,并传给linear(cell_output, new_attn)。  
  #函数做一个权重映射，最后得到的output=[batch_size,output_size]  
  with variable_scope.variable_scope(&quot;AttnOutputProjection&quot;):
    output = linear([cell_output] + attns, output_size, True)
  if loop_function is not None:
    prev = output
  outputs.append(output)
return outputs, state
</code></pre><h3 id="2-3-sampled-softmax"><a href="#2-3-sampled-softmax" class="headerlink" title="2.3 sampled softmax"></a>2.3 sampled softmax</h3><p>在英法翻译例子代码中调用了sampled_softmax_loss()这个损失函数来计算损失值。<br>在tf的官网中给出了两份参考资料：<br>(1) Candidate Sampling Algorithms Reference (<a href="https://www.tensorflow.org/versions/r0.12/extras/candidate_sampling.pdf" target="_blank" rel="external">https://www.tensorflow.org/versions/r0.12/extras/candidate_sampling.pdf</a>)<br>里面介绍了什么是candidate sampling以及几种常见的candidate sampling的算法。</p>
<p>(2) 一篇论文：On Using Very Large Target Vocabulary for Neural Machine Translation(<a href="https://arxiv.org/abs/1412.2007),论文中介绍了在目标词汇表很大的时候" target="_blank" rel="external">https://arxiv.org/abs/1412.2007),论文中介绍了在目标词汇表很大的时候</a><br>可以采用采样(sampling)的方法来替代full softmax，降低计算复杂度。  </p>
<p>总结以上两份资料，简述candidate sampling和sampled_softmax_loss()<br>损失函数的作用在于计算模型的输出和真实值之间的距离。<br>和candidate sampling训练方法相对应的是Exhaustive训练方法(比如softmax)。<br>在多标签或者多分类问题上，当分类的可能目标值很大的时候，比如英法翻译，每一个英文单词要在整个法语词表上计算是每一个法语单词的概率，例子中法语词表数值为40000，这样的计算代价很大。<br>所以Yoshua Bengio大牛就在On Using Very Large Target Vocabulary for Neural Machine Translation这篇文章中提出，找到一种方法来替代Exhaustive训练方法。每次选取词表中一小部分的子集和训练样例的标签集来组成一个新的集合，这个新的集合的包含的单词数量远远小于目标词表的数量，这样计算起来就会简单很多。  </p>
<p>下图直观的说明了full softmax和sample softmax的区别和联系：<br><img src="http://ojigevmih.bkt.clouddn.com/sampled_softmax.png" alt=""><br>(picture from:On Using Very Large Target Vocabulary for Neural Machine Translation)</p>
<p>在英法翻译例子中：法语词表=40000，num_samples=512,就是每次选出512个子集再加上训练集的标签集来计算每个单词在新的词表集合中的概率分布。因为num_samples远远小于词表数，所以计算会简单不少。</p>
<p>至于如何进行采样，在tf中给了几种采样器：均匀采样，齐夫定律采样等等。根据需要调用就可以。</p>
<h3 id="2-4-output-projection"><a href="#2-4-output-projection" class="headerlink" title="2.4 output_projection"></a>2.4 output_projection</h3><p>output_projection在tf中是一个很重要的机制，对于处理large output vocabulary的问题来讲可以很好的节约空间。  </p>
<h4 id="2-4-1-output-projection-基本说明"><a href="#2-4-1-output-projection-基本说明" class="headerlink" title="2.4.1 output_projection 基本说明"></a>2.4.1 output_projection 基本说明</h4><p>output_projection作为一个重要的参数在tf的seq2seq模型中传播，它的值有两个，第一个是None，第二个是一个tuple=(W,B)。下面对这两种情况进行说明：  </p>
<h5 id="1-output-projection-None"><a href="#1-output-projection-None" class="headerlink" title="1.  output_projection=None"></a>1.  output_projection=None</h5><p>None代表着不采用output_projection机制，此时从tf给的seq2seq模型中的输出结果的维度是output=[batch_size , num_decoder_symbols]。  </p>
<p>batch_size是深度学习中训练数据的一种方式，每次选取一个小的batch的数据去训练，然后计算这个batch的损失函数值，模型的训练目标让每一个batch的损失函数值逐渐减小。该方法是从SGD和GD中选取的一个折中的方法。  </p>
<p>Num_decoder_symbols指decoder的输入的特征数。比如在英法翻译中，法语作为目标语言的输入，num_decoder_symbols是选取的法语特征的单词数，即法语词表的数值大小。  </p>
<p>在英法翻译例子代码中batch_size=64, num_decoder_symbols=40000。如果不采用output_projection,每一个时间步的输出的维度为：output=[64,40000]，需要耗费很大的存储空间。  </p>
<h5 id="2-output-projection-W-B"><a href="#2-output-projection-W-B" class="headerlink" title="2.  output_projection=(W,B)"></a>2.  output_projection=(W,B)</h5><p>W是一个权重权矩阵，W的维度是[size , num_decoder_symbols]，B是一个偏置向量，B的维度是[num_decoder_symbols]。采用output_projection=(W,B)时，tf给的seq2seq模型中的输出结果的维度是 output=[batch_size , size]。<br>在英法翻译例子代码中size=1024,batch_size=64, num_decoder_symbols=40000  </p>
<h4 id="2-4-2-output-projection的核心思想"><a href="#2-4-2-output-projection的核心思想" class="headerlink" title="2.4.2 output_projection的核心思想"></a>2.4.2 output_projection的核心思想</h4><p>output_projection的核心思想是：<br>在模型训练时，当num_decoder_symbols=40000时，值很大，不便于存储和计算，用一个较小的值size=1024来代替。这样所需要耗费的存储资源就会少很多，计算速度也会提升。因此在英法翻译例子代码中采用了这种方式。<br>当模型测试时，再将output=[batch_size, size]和W=[size,num_decoder_symbols]做矩阵乘，再加上偏置B，得到最后的输出final_output=[batch_size, num_decoder_symbols]，该过程相当于是做一个维度映射，size映射到num_decoder_symbols。<br>最后得到的final_output是每一个词在目标语言词表上的概率分布。  </p>
<h4 id="2-4-3-具体代码中的output-projection"><a href="#2-4-3-具体代码中的output-projection" class="headerlink" title="2.4.3 具体代码中的output_projection"></a>2.4.3 具体代码中的output_projection</h4><h5 id="1-output-projection的产生和调用-在seq2seq-model-py中"><a href="#1-output-projection的产生和调用-在seq2seq-model-py中" class="headerlink" title="1.  output_projection的产生和调用,在seq2seq_model.py中"></a>1.  output_projection的产生和调用,在seq2seq_model.py中</h5><pre><code> #初始化output_projection=None
output_projection = None
if num_samples &gt; 0 and num_samples &lt; self.target_vocab_size:
  w_t = tf.get_variable(&quot;proj_w&quot;, [self.target_vocab_size, size], dtype=dtype)
  w = tf.transpose(w_t)
  b = tf.get_variable(&quot;proj_b&quot;, [self.target_vocab_size], dtype=dtype)
  output_projection = (w, b)
</code></pre><p> output_projection不做任何改变，作为参数传递到tf.nn.seq2seq.embedding_attention_seq2seq()</p>
<pre><code>return tf.nn.seq2seq.embedding_attention_seq2seq(
      encoder_inputs,
      decoder_inputs,
      cell,
      num_encoder_symbols=source_vocab_size,
      num_decoder_symbols=target_vocab_size,
      embedding_size=size,
      output_projection=output_projection,
      feed_previous=do_decode,
      dtype=dtype)
</code></pre><p>seq2seq.embedding_attention_seq2seq()的默认参数中output_projection=None ,但是这里output_projection=(w,b)     </p>
<h5 id="2-output-projection进入tf的库函数tf-nn-ops-seq2seq-py中"><a href="#2-output-projection进入tf的库函数tf-nn-ops-seq2seq-py中" class="headerlink" title="2.  output_projection进入tf的库函数tf.nn.ops.seq2seq.py中"></a>2.  output_projection进入tf的库函数tf.nn.ops.seq2seq.py中</h5><p>seq2seq.py中包括了tf的所有seq2seq的模型函数，比如basic_rnn_seq2seq,embedding_rnn_seq2seq,embedding_attention_decoder等一系列模型。  </p>
<pre><code>进入seq2seq.embedding_attention_seq2seq()中之后output_projection的传递过程如下：


   embedding_attention_seq2seq()      
   --&gt; embedding_attention_decoder()    
   --&gt; attention_decoder()
   --&gt;_extract_argmax_and_embed()  
   --&gt;loop_function()
   --&gt;最终的实现代码：  
       if output_projection is not None:
         prev = nn_ops.xw_plus_b(
             prev, output_projection[0], output_projection[1])

       #注括号中的prev是上一时刻RNN的output,prev=[batch_size,size]
       #output_projection=[size,num_decoder_symbols]  
       #在本例中batch_size=64,size=1024,num_decoder_symbols=40000
       #最终经过映射后的prev=[batch_size,num_decoder_symbols]=[64,4000]
</code></pre><p>从上面的代码其实很容易就可以看出来，output_projection的功能就是维度映射，        </p>
<h3 id="2-5-Tensorflow中的Padding与bucketing"><a href="#2-5-Tensorflow中的Padding与bucketing" class="headerlink" title="2.5 Tensorflow中的Padding与bucketing"></a>2.5 Tensorflow中的Padding与bucketing</h3><p>在Seq2seq模型中仍然是只能够处理定长sequence到定长sequence的问题，但是常见的sequence到sequence的任务，比如翻译任务、QA任务、Chatbot任务，一般输入的sequence和输出的sequence长度都是不相同的，都是变长到变长。<br>对于变长到变长，一般的处理方式就是通过padding（填充）到固定长度，将变长到变长的问题转换成为定长到定长的问题。  </p>
<p>在Tensorflow中为输入数据提供了三种Padding的方式：Static Padding、Dynamic Padding、BUcketing。<br>(1) Static Padding：不论序列原始长度是多少，预先都将所有的输入和输出都各自Padding到一个固定的长度。见下图：<br><img src="http://ojigevmih.bkt.clouddn.com/static%20padding.png" alt=""><br>（假设batch_size=3，图中灰色部分是进行Padding的长度）  </p>
<p>(2) Dynamic Padding：该方式不对所有序列预先Padding到一个固定长度，而是对每一个batch取其中最长的那个序列的长度L，然后对该batch中所有的序列都进行动态Padding到L长度，所以每一个Batch的长度L可能不一样。<br><img src="http://ojigevmih.bkt.clouddn.com/dynamic%20padding.png" alt=""><br>（假设batch_size=3，图中灰色部分是进行Padding的长度）  </p>
<p>(3) Bucketing：<br><img src="http://ojigevmih.bkt.clouddn.com/bucketing.png" alt=""><br>该方法是首先定义一系列长度的Buckets.<br>Eg:英法翻译例子中的buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]<br>该buckets是一个List，每一个元素是一个tuple，表示(encoder_input_size,decoder_input_size)。该方法相当于是对所有的样本根据encoder_input和decoder_input的长度进行分类，每一类中输入和输出句子都有固定的长度。比如在英法翻译中，如果英文句子(源语言)长度为3，法语句子(目标语言)长度为7，那么就将其放入(5,10)这一类中。如果英文句子长度为8，法文句子长度为12，将其放入(10,15)这一类中。<br>相比第一种，当序列自身的长度很短的时候，使用第一种方式则会很浪费空间。<br>相比第二种，第二种方法动态Padding的方法，会产生很多子图，会浪费很多时间<br>相比前面两种方法来说，Bucketing方法可以更加高效的处理不同长度的句子。  </p>
<h3 id="2-6-Tensorflow中的feed-previous"><a href="#2-6-Tensorflow中的feed-previous" class="headerlink" title="2.6  Tensorflow中的feed_previous"></a>2.6  Tensorflow中的feed_previous</h3><h4 id="2-6-1-feed-previous介绍"><a href="#2-6-1-feed-previous介绍" class="headerlink" title="2.6.1 feed_previous介绍"></a>2.6.1 feed_previous介绍</h4><p>在seq2seq的decoder中，decoder_inputs的产生有两种机制，第一种是将decoder 在t时刻的output作为t+1时刻的input，第二种是将t+1时刻的decoder_inputs[t+1] 作为t+1时刻的input。<br>一般的策略是在训练的时候采用第二种机制，即每一个时间步都采用正确的输入，也就是decoder_inputs[t]。在测试的时候采用第一种机制。  </p>
<p>更进一步来讲，feed_previous的机制就是采用一个布尔值来进行控制。<br>当Feed_previous=True的时候，用于测试，表明采用第一种机制，decoder只会将decoder_inputs的第一个元素作为输入，第一个元素一般是一个形式标记，一般是<eos>或者<go>这一类似的标记，以后则将t时刻的输出作为t+1时刻的输入，因为测试时候的decoder_inputs是未知的。  </go></eos></p>
<p>当feed_previous=False的时候，是训练过程，表明采用第二种机制，以此提高模型训练的正确性，这也是为什么在前面说seq2seq是一个有监督的模型。<br>假设采用feed_previous=True,采用t时刻的output作为t+1时刻的input,当output有错误时，将不能正确的预测t+1时刻的output,这个错误便会一直被传播下去,直接模型的性能不好。因此在训练过程中一般采用feed_previous=False。</p>
<h4 id="2-6-2-feed-previous和output-projection的联系"><a href="#2-6-2-feed-previous和output-projection的联系" class="headerlink" title="2.6.2 feed_previous和output_projection的联系"></a>2.6.2 feed_previous和output_projection的联系</h4><p>在attention_embedding_seq2seq这个模型中，feed_previous和output_projection有着直接的关系的。output_projection的最终执行代码是写在一个叫做loop_function的函数中的。  </p>
<p>当feed_previous=False时，不使用t时刻的output作为t+1时刻的input,此时loop_function=False，不会执行和output_projection相关的代码，此时output_projection有或者没有都不会有影响。   </p>
<p>当feed_previou=True的时候，并且output_projection is not None时，就会调用loop_function中的代码，利用output_projection做一个映射。</p>
<p>理解了上面的机制后，再去看translate目录下的代码就容易很多，此处就不再进行其他代码的解析了。</p>
<h2 id="3-模型真正跑起来"><a href="#3-模型真正跑起来" class="headerlink" title="3.模型真正跑起来"></a>3.模型真正跑起来</h2><h3 id="3-1-WMT语料下"><a href="#3-1-WMT语料下" class="headerlink" title="3.1 WMT语料下"></a>3.1 WMT语料下</h3><p>进入translate目录下，输入 python translate.py，模型就开始执行。<br>这份代码中没有设置让训练停下来的参数，要想停止模型只有手动在终端下ctrl+C停止程序运行。模型的每一轮参数都有保存，所以在下次想要运行之前训练的模型的时候只需要在translate目录下输入：python translate.py –decode，就可以进入在终端进行测试，测试方法是输入一个英文句子，模型会给出一个该英文句子对应的法文翻译。</p>
<p>这个代码亲自运行过，是可以运行成功的，但是要想训练一个不错的翻译模型需要跑很久，官网上说大概需要350000次。因为设备有限就没有跑那么多次来测试它的性能。</p>
<h3 id="3-2-杜撰的语料"><a href="#3-2-杜撰的语料" class="headerlink" title="3.2 杜撰的语料"></a>3.2 杜撰的语料</h3><p>  总共产生了100000个训练例，100个测试例。其中encoder_input=decoder_input，即期待模型的输出和输入相同。其中encoder_input的值选取从0到100之间的整数值。</p>
<p>  数据产生方式如下：<br>    for i in range(data_num):<br>      encoder_size = random.randint(4,30)<br>      decoder_size = encoder_size<br>      encoder_input = (np.random.choice(np.arange(0, 100),<br>                      size=(encoder_size,), replace=False))<br>      decoder_input = encoder_input</p>
<p>模型修改了下面个参数，其余的所有都保持不变。<br>修改后：<br>batch_size=10<br>size=128(词向量的维度)<br>num_layers= 2(RNN的层数)<br>vocab_size=512(词表的大小)</p>
<p>修改前：<br>batch_size=64<br>size=1024<br>num_layers= 3<br>en_vocab_size=fr_vocab_size=40000</p>
<p>模型训练的步数：801800<br>最终得到的实验结果：<br><img src="http://ojigevmih.bkt.clouddn.com/fakedata_seq2seq_result.png" alt=""></p>
<p>可以看出：模型给的输出是在往输入靠拢的，但是还是没有完全的等于输入数据。应该是还需要调整模型的参数或者是增加训练时间。</p>
<h2 id="4-参考资源"><a href="#4-参考资源" class="headerlink" title="4.参考资源"></a>4.参考资源</h2><p>tensorflow官网：<a href="https://www.tensorflow.org/" target="_blank" rel="external">https://www.tensorflow.org/</a><br>tensorflow github：<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">https://github.com/tensorflow/tensorflow</a><br>tensorlayer: <a href="http://tensorlayer.readthedocs.io/en/latest/index.html" target="_blank" rel="external">http://tensorlayer.readthedocs.io/en/latest/index.html</a></p>
<p>paper:<br>Learning Phrase Representations using RNN encoder–decoder for Statistical Machine Translation<br>Sequence to Sequence Learning with Neural Networks<br>Neural Machine Translation By Joint Learning to Align and Translate<br>Grammar as a Foreign Language<br>On Using Very Large Target Vocabulary for Neural Machine Translation<br>candidate_sampling</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/seq2seq/" rel="tag"># seq2seq</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/09/my-first-blog/" rel="next" title="my first blog">
                <i class="fa fa-chevron-left"></i> my first blog
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://ojigevmih.bkt.clouddn.com/20170110.jpg"
               alt="chunhualiu" />
          <p class="site-author-name" itemprop="name">chunhualiu</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-基础知识"><span class="nav-number">1.</span> <span class="nav-text">1.基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-Tensorflow简介"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 Tensorflow简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-关于Neural-Machine-Learning-NMT-简介"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 关于Neural Machine Learning(NMT)简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-英法翻译例子代码介绍"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 英法翻译例子代码介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-1-数据集"><span class="nav-number">1.3.1.</span> <span class="nav-text">1.3.1  数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-2-代码构成"><span class="nav-number">1.3.2.</span> <span class="nav-text">1.3.2  代码构成</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-embedding-attention-seq2seq中的机制"><span class="nav-number">2.</span> <span class="nav-text">2. embedding_attention_seq2seq中的机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-sequence2sequence-model介绍"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 sequence2sequence model介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Attention-Mechanism"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 Attention Mechanism</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-Attention-Mechanism-Theory"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1 Attention Mechanism Theory</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-Attention-Mechanism-Code"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2 Attention Mechanism Code</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-attention-部分"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">1.attention 部分</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-attention-decoder-核心代码流程"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">2.attention_decoder()  核心代码流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-sampled-softmax"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 sampled softmax</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-output-projection"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 output_projection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-1-output-projection-基本说明"><span class="nav-number">2.4.1.</span> <span class="nav-text">2.4.1 output_projection 基本说明</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-output-projection-None"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">1.  output_projection=None</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-output-projection-W-B"><span class="nav-number">2.4.1.2.</span> <span class="nav-text">2.  output_projection=(W,B)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-2-output-projection的核心思想"><span class="nav-number">2.4.2.</span> <span class="nav-text">2.4.2 output_projection的核心思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-3-具体代码中的output-projection"><span class="nav-number">2.4.3.</span> <span class="nav-text">2.4.3 具体代码中的output_projection</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-output-projection的产生和调用-在seq2seq-model-py中"><span class="nav-number">2.4.3.1.</span> <span class="nav-text">1.  output_projection的产生和调用,在seq2seq_model.py中</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-output-projection进入tf的库函数tf-nn-ops-seq2seq-py中"><span class="nav-number">2.4.3.2.</span> <span class="nav-text">2.  output_projection进入tf的库函数tf.nn.ops.seq2seq.py中</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-Tensorflow中的Padding与bucketing"><span class="nav-number">2.5.</span> <span class="nav-text">2.5 Tensorflow中的Padding与bucketing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-Tensorflow中的feed-previous"><span class="nav-number">2.6.</span> <span class="nav-text">2.6  Tensorflow中的feed_previous</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-6-1-feed-previous介绍"><span class="nav-number">2.6.1.</span> <span class="nav-text">2.6.1 feed_previous介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-6-2-feed-previous和output-projection的联系"><span class="nav-number">2.6.2.</span> <span class="nav-text">2.6.2 feed_previous和output_projection的联系</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-模型真正跑起来"><span class="nav-number">3.</span> <span class="nav-text">3.模型真正跑起来</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-WMT语料下"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 WMT语料下</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-杜撰的语料"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 杜撰的语料</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-参考资源"><span class="nav-number">4.</span> <span class="nav-text">4.参考资源</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">chunhualiu</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  




  
  

  

  

  

  


</body>
</html>
